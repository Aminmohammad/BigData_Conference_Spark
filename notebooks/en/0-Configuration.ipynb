{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "EXT = ('.tgz', '.tar.gz')\n",
    "\n",
    "def md5(fname):\n",
    "    hash = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash.update(chunk)\n",
    "    return hash.hexdigest()\n",
    "\n",
    "def download_check_extract(path, url, files, md5s):\n",
    "    # Create destination folder if it does not exist\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # Download archives and verify checkums\n",
    "    for file_, md5_ in zip(files, md5s):\n",
    "        file_path = os.path.join(path, file_)\n",
    "        if not os.path.exists(file_path):\n",
    "            urlretrieve(urljoin(url,file_), file_path)\n",
    "        else:\n",
    "            print('File already downloaded, checking MD5.')\n",
    "        correct = md5_ == md5(file_path)\n",
    "        print(\"{file} {status}\".format(file=file_, status=('OK' if correct else 'BAD')))\n",
    "        \n",
    "        # Extract tarball if checksum is correct\n",
    "        if correct:\n",
    "            if any(file_.endswith(ext) for ext in EXT):\n",
    "                with tarfile.open(file_path, 'r:gz') as tar:\n",
    "                    os.chdir(path)\n",
    "                    tar.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia PageCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LOCAL_PATH = 'data/pagecounts'\n",
    "URL = 'https://dumps.wikimedia.org/other/pagecounts-raw/2009/2009-05/'\n",
    "ARCHIVES = ['pagecounts-20090501-000000.gz','pagecounts-20090501-010000.gz','pagecounts-20090501-020000.gz']\n",
    "MD5 = ['1c03c14c2432d572824fc73ae9b30139', 'd8b23af53466d1893221ff766fedd010', '3623b189e28dfa5387b3e0fc82779c66']\n",
    "\n",
    "download_check_extract(LOCAL_PATH, URL, ARCHIVES, MD5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Complete Works of William Shakespeare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LOCAL_PATH = 'data/shakespeare'\n",
    "URL = 'http://sydney.edu.au/engineering/it/~matty/Shakespeare/'\n",
    "FILES = ['shakespeare.tar.gz']\n",
    "MD5 = ['d9e012cb9c7f1509a1c5c59cf6e3a7e6']\n",
    "\n",
    "download_check_extract(LOCAL_PATH, URL, FILES, MD5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Oxford Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LOCAL_PATH = 'data/flowers'\n",
    "URL = 'http://www.robots.ox.ac.uk/~vgg/data/flowers/102/'\n",
    "ARCHIVES = ['102flowers.tgz']\n",
    "MD5 = ['52808999861908f626f3c1f4e79d11fa']\n",
    "\n",
    "download_check_extract(LOCAL_PATH, URL, ARCHIVES, MD5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
